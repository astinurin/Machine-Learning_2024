{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implementasi Normalisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.16666666666666666, 0.3333333333333333, 0.6666666666666666, 1.0]\n"
     ]
    }
   ],
   "source": [
    "def norm_data(data):\n",
    "    '''\n",
    "    Melakukan normalisasi data.\n",
    "\n",
    "    Parameters:\n",
    "    data (list) : Data yang akan dinormalisasi\n",
    "\n",
    "    Returns:\n",
    "    data (list) : Data hasil normalisasi\n",
    "    \n",
    "    '''\n",
    "    data_max = max(data)\n",
    "    data_min = min(data)\n",
    "    data_len = len(data)\n",
    "\n",
    "    for i in range(data_len):\n",
    "        data[i] = (data[i] - data_min) / (data_max - data_min)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Contoh Penggunaan\n",
    "data = [10, 11, 12, 14, 16]\n",
    "n_data = norm_data(data)\n",
    "print(n_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implementasi normalisasi dengan\n",
    "menggunakan library Scikit-learn untuk kasus data fitur dalam bentuk 2 dimensi\n",
    "(2d list atau 2d array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Asli\n",
      "[[100.       0.0001]\n",
      " [ 50.       0.05  ]\n",
      " [ 30.       0.003 ]]\n",
      "Data Normalisasi\n",
      "[[1.       0.      ]\n",
      " [0.285714 1.      ]\n",
      " [0.       0.058116]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "np.set_printoptions(precision=6)  # bulatkan 4 angka koma\n",
    "np.set_printoptions(suppress=True)  # hilangkan nilai e\n",
    "\n",
    "# Kita akan membentuk data\n",
    "# Hal ini dikarenakan, scikit-learn hanya menerima input\n",
    "# dalam bentuk n-dimensional array\n",
    "data = [\n",
    "    [100, 0.0001],\n",
    "    [50, 0.05],\n",
    "    [30, 0.003]\n",
    "]\n",
    "\n",
    "# Ubah ke bentuk numpy n-dimensional array\n",
    "data = np.asarray(data)\n",
    "print('Data Asli')\n",
    "print(data)\n",
    "\n",
    "# Mendefinisikan objek MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# Transformasikan data\n",
    "scaled = scaler.fit_transform(data)\n",
    "print('Data Normalisasi')\n",
    "print(scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implementasi Standarisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Asli\n",
      "[[100.       0.0001]\n",
      " [ 50.       0.05  ]\n",
      " [ 30.       0.003 ]]\n",
      "Data Standarisasi\n",
      "[[ 1.358732 -0.76956 ]\n",
      " [-0.339683  1.412317]\n",
      " [-1.019049 -0.642757]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler #memanggil kelas ‘StandardScaler’\n",
    "\n",
    "np.set_printoptions(precision=6)  # bulatkan 4 angka koma\n",
    "np.set_printoptions(suppress=True)  # hilangkan nilai e\n",
    "\n",
    "# Kita akan membentuk data\n",
    "# Hal ini dikarenakan, scikit-learn hanya menerima input\n",
    "# dalam bentuk n-dimensional array\n",
    "data = [\n",
    "    [100, 0.0001],\n",
    "    [50, 0.05],\n",
    "    [30, 0.003]\n",
    "]\n",
    "\n",
    "# Ubah ke bentuk numpy n-dimensional array\n",
    "data = np.asarray(data)\n",
    "print('Data Asli')\n",
    "print(data)\n",
    "\n",
    "# Mendefinisikan objek StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Transformasikan data\n",
    "scaled = scaler.fit_transform(data)\n",
    "print('Data Standarisasi')\n",
    "print(scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implementasi Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Asli\n",
      "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri Jakarata'], ['Politeknik Negeri Semarang']]\n",
      "Data Transformasi Ordinal Encoder\n",
      "[[2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [3.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder #mengimport kelas ‘OrdinalEncoder’\n",
    "# Inisiasi obyek Ordinal Encoder\n",
    "oe = OrdinalEncoder()\n",
    "# Definisikan data\n",
    "# dalam bentuk 2d\n",
    "data= [\n",
    "['Politeknik Negeri Malang'],\n",
    "['Politeknik Elektronika Negeri Surabaya'],\n",
    "['Politeknik Negeri Jakarata'],\n",
    "['Politeknik Negeri Semarang']\n",
    "]\n",
    "# Transformasi Ordinal Encoder\n",
    "transform_oe = oe.fit_transform(data)\n",
    "print('Data Asli')\n",
    "print(data)\n",
    "print('Data Transformasi Ordinal Encoder')\n",
    "print (transform_oe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Implementasi One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Asli\n",
      "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri Jakarta'], ['Politeknik Negeri Semarang']]\n",
      "Data Transformasi One-Hot Encoding\n",
      "[[0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Inisiasi obyek Ordinal Encoder\n",
    "ohe = OneHotEncoder()\n",
    "# Definisikan data\n",
    "# dalam bentuk 2d\n",
    "data = [\n",
    "['Politeknik Negeri Malang'],\n",
    "['Politeknik Elektronika Negeri Surabaya'],\n",
    "['Politeknik Negeri Jakarta'],\n",
    "['Politeknik Negeri Semarang']\n",
    "]\n",
    "# Transformasi Ordinal Encoder\n",
    "transform_ohe=ohe.fit_transform(data)\n",
    "print('Data Asli')\n",
    "print(data)\n",
    "\n",
    "print('Data Transformasi One-Hot Encoding')\n",
    "print(transform_ohe.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Implementasi Dummy Variable Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Asli\n",
      "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri Jakarta'], ['Politeknik Negeri Semarang']]\n",
      "Data Transformasi One-Hot Encoding\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#Inisiasi obyek Ordinal Encoder\n",
    "de = OneHotEncoder(drop='first')\n",
    "#Definisikan data\n",
    "# dalam bentuk 2d\n",
    "data= [\n",
    "['Politeknik Negeri Malang'],\n",
    "['Politeknik Elektronika Negeri Surabaya'],\n",
    "['Politeknik Negeri Jakarta'],\n",
    "['Politeknik Negeri Semarang']\n",
    "]\n",
    "#Transformasi Ordinal Encoder\n",
    "transform_de = de.fit_transform(data)\n",
    "print('Data Asli')\n",
    "print(data)\n",
    "print('Data Transformasi One-Hot Encoding')\n",
    "print(transform_de.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Studi Kasus Ekstrasi Fitur dari Data Teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'the house had a tiny little mouse',\n",
    "    'the cat saw the mouse',\n",
    "    'the mouse ran away from the house',\n",
    "    'the cat finally ate the mouse',\n",
    "    'the end of the mouse story'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7)\t0.2808823162882302\n",
      "  (0, 6)\t0.5894630806320427\n",
      "  (0, 11)\t0.5894630806320427\n",
      "  (0, 5)\t0.47557510189256375\n",
      "  (1, 9)\t0.7297183669435993\n",
      "  (1, 2)\t0.5887321837696324\n",
      "  (1, 7)\t0.3477147117091919\n",
      "  (2, 1)\t0.5894630806320427\n",
      "  (2, 8)\t0.5894630806320427\n",
      "  (2, 7)\t0.2808823162882302\n",
      "  (2, 5)\t0.47557510189256375\n",
      "  (3, 0)\t0.5894630806320427\n",
      "  (3, 4)\t0.5894630806320427\n",
      "  (3, 2)\t0.47557510189256375\n",
      "  (3, 7)\t0.2808823162882302\n",
      "  (4, 10)\t0.6700917930430479\n",
      "  (4, 3)\t0.6700917930430479\n",
      "  (4, 7)\t0.3193023297639811\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Inisiasi obyek TfidfVectorizer\n",
    "vect = TfidfVectorizer(stop_words= 'english')\n",
    "\n",
    "#Pembobotan TF-IDF\n",
    "resp=vect.fit_transform(corpus)\n",
    "\n",
    "# Cetak Hasil\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil TF-IDF\n",
      "  (0, 7)\t0.2808823162882302\n",
      "  (0, 6)\t0.5894630806320427\n",
      "  (0, 11)\t0.5894630806320427\n",
      "  (0, 5)\t0.47557510189256375\n",
      "  (1, 9)\t0.7297183669435993\n",
      "  (1, 2)\t0.5887321837696324\n",
      "  (1, 7)\t0.3477147117091919\n",
      "  (2, 1)\t0.5894630806320427\n",
      "  (2, 8)\t0.5894630806320427\n",
      "  (2, 7)\t0.2808823162882302\n",
      "  (2, 5)\t0.47557510189256375\n",
      "  (3, 0)\t0.5894630806320427\n",
      "  (3, 4)\t0.5894630806320427\n",
      "  (3, 2)\t0.47557510189256375\n",
      "  (3, 7)\t0.2808823162882302\n",
      "  (4, 10)\t0.6700917930430479\n",
      "  (4, 3)\t0.6700917930430479\n",
      "  (4, 7)\t0.3193023297639811\n",
      "Hasil Token\n",
      "['ate' 'away' 'cat' 'end' 'finally' 'house' 'little' 'mouse' 'ran' 'saw'\n",
      " 'story' 'tiny']\n"
     ]
    }
   ],
   "source": [
    "from sklearn. feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'the house had a tiny little mouse',\n",
    "    'the cat saw the mouse',\n",
    "    'the mouse ran away from the house',\n",
    "    'the cat finally ate the mouse',\n",
    "    'the end of the mouse story'\n",
    "]\n",
    "\n",
    "# Inisiasi obyek TFidfVectorizer\n",
    "vect = TfidfVectorizer (stop_words='english' )\n",
    "\n",
    "# Pembobotan TF-IDF\n",
    "resp = vect.fit_transform(corpus)\n",
    "\n",
    "# Cetak hasil\n",
    "print('Hasil TF-IDF')\n",
    "print(resp)\n",
    "\n",
    "# Cetak token hasil stopword\n",
    "print('Hasil Token')\n",
    "print(vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TUGAS PRAKTIKUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil TF-IDF:\n",
      "  (0, 7)\t0.2808823162882302\n",
      "  (0, 6)\t0.5894630806320427\n",
      "  (0, 11)\t0.5894630806320427\n",
      "  (0, 5)\t0.47557510189256375\n",
      "  (1, 9)\t0.7297183669435993\n",
      "  (1, 2)\t0.5887321837696324\n",
      "  (1, 7)\t0.3477147117091919\n",
      "  (2, 1)\t0.5894630806320427\n",
      "  (2, 8)\t0.5894630806320427\n",
      "  (2, 7)\t0.2808823162882302\n",
      "  (2, 5)\t0.47557510189256375\n",
      "  (3, 0)\t0.5894630806320427\n",
      "  (3, 4)\t0.5894630806320427\n",
      "  (3, 2)\t0.47557510189256375\n",
      "  (3, 7)\t0.2808823162882302\n",
      "  (4, 10)\t0.6700917930430479\n",
      "  (4, 3)\t0.6700917930430479\n",
      "  (4, 7)\t0.3193023297639811\n",
      "Hasil Token:\n",
      "['ate' 'away' 'cat' 'end' 'finally' 'house' 'little' 'mouse' 'ran' 'saw'\n",
      " 'story' 'tiny']\n"
     ]
    }
   ],
   "source": [
    "# Proses Ekstraksi Fitur TF-IDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Membaca file corpus.txt (tambahan)\n",
    "with open('corpus.txt', 'r') as file:\n",
    "    corpus = file.readlines()\n",
    "\n",
    "# Inisiasi obyek TfidfVectorizer\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Pembobotan TF-IDF\n",
    "resp = vect.fit_transform(corpus)\n",
    "\n",
    "# Cetak hasil\n",
    "print('Hasil TF-IDF:')\n",
    "print(resp)\n",
    "\n",
    "# Cetak token hasil stopword\n",
    "print('Hasil Token:')\n",
    "print(vect.get_feature_names_out())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
